# Поиск близости через данные  

## Или как алгоритмы научились понимать человеческие предпочтения  

---

### Задача  

Найти существующего пользователя из базы данных, который максимально схож с новым пользователем по его поведению и предпочтениям. Также определить категории активности, которые наиболее влияют на схожесть между пользователями. Задача интересна тем, что использует в своем решении векторное представление пользователей для анализа многомерных данных. В решении применяется косинусное сходство — метрику, которая эффективно работает в высокоразмерных пространствах.  

### Зачем это нужно?  

1. **Рекомендательные системы**: Если новый пользователь похож на пользователя X, ему можно предлагать тот же контент или товары.  
2. **Кластеризация данных**: Новый пользователь может быть автоматически отнесен к группе схожих пользователей, что помогает в сегментации аудитории.  
3. **Поиск аномалий**: Если сходство нового пользователя с существующими низкое, это может указывать на подозрительную активность или уникальные предпочтения.  

---

### Данные  

Предпочтения 10 пользователей хранятся в таблице `users_stats`:

| User ID | Смартфон | Телевизор | Ноутбук | Шкаф | Холодильник | Посуда |  
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |  
| 1 | 2 | 1 | 0 | 0 | 0 | 0 |  
| 2 | 1 | 1 | 2 | 1 | 0 | 0 |  
| 3 | 2 | 0 | 1 | 0 | 0 | 0 |  
| 4 | 1 | 1 | 2 | 1 | 0 | 1 |  
| 5 | 0 | 0 | 1 | 2 | 0 | 0 |  
| 6 | 0 | 0 | 0 | 0 | 0 | 5 |  
| 7 | 1 | 0 | 0 | 0 | 0 | 0 |  
| 8 | 0 | 1 | 1 | 0 | 0 | 0 |  
| 9 | 0 | 0 | 0 | 1 | 1 | 3 |  
| 10 | 1 | 0 | 0 | 2 | 1 | 4 |  

---

### Решение  

**Каждый человек — это вектор**:

Пользователь — это уникальная личность, но с точки зрения математики мы можем представить его как точку или стрелку (вектор) в многомерном пространстве. Например:
- Если у нас есть данные о покупках пользователей в интернет-магазине, то каждый пользователь можно описать вектором, где компоненты — это количество покупок различных категорий товаров.
- Если у нас есть данные о фильмах, которые пользователи смотрят, то каждый пользователь можно описать вектором, где компоненты — это рейтинги фильмов.

Математически это выглядит так:

$$
\vec{a} = [a_1, a_2, \dots, a_n]
$$

или

$$
\vec{\text{new}\textunderscore\text{user}\textunderscore\text{stats}} = [0, 1, 2, 0, 0, 0]
$$

Матрица `users_stats` — это набор векторов в 6-мерном пространстве  описывающий поведение конкретного человека. 
Математически это выглядит так:

$$
users \textunderscore stats_{m,n} =
\begin{bmatrix}
  \vec{a_1} \\
  \vec{a_2} \\
  \vdots  \\
  \vec{a_m}
\end{bmatrix} =
\begin{bmatrix}
  a_{1,1} & a_{1,2} & \cdots & a_{1,n} \\
  a_{2,1} & a_{2,2} & \cdots & a_{2,n} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  a_{m,1} & a_{m,2} & \cdots & a_{m,n}
\end{bmatrix}
$$

где:\
$m$ — количество пользователей в данных интернет-магазина,\
$n$ — количество столбцов по количеству категорий активности.

**Мера схожести**:
#### 1. Как же измерить схожесть направления стрелок?
- Если стрелки указывают в одном направлении — вкусы пропорционально одинаковы.
- Если стрелки перпендикулярны — вкусы не связаны.
- Если стрелки направлены противоположно — вкусы противоположны.

#### 2. Угол между стрелками
- Угол между двумя стрелками — это мера их схожести.
- Чем меньше угол, тем ближе стрелки направлены — тем более похожи вкусы.

#### 3. Как вычислить угол?
Из школьного курса геометрии мы знаем, что косинус угла между двумя векторами можно найти через их скалярное произведение и длины по формуле косинусного сходства:
- Косинусное сходство $\cos(\theta)$ используется для сравнения направлений векторов.  
- Формула косинусного сходства:

$$
cos(\theta) = \frac{\vec{a} \cdot \vec{b}}{|\vec{a}| \cdot |\vec{b}|}
$$

где:\
$\vec{a}$ и $\vec{b}$ — векторы нового пользователя `new_user_stats` и существующего пользователя из базы данных,\
$|\vec{a}|$ и $|\vec{b}|$ — нормы (длины) векторов.  

Для наглядности дальнейших вычислений нашу формулу косинусного сходства можно выразить еще вот так:

$$
cos(\theta) = \frac{\text{скалярное произведение}}{|\text{норма нового пользователя}| \times |\text{норма текущего пользователя}|}
$$

**Скалярное произведение**:  
   - Вычисляется как сумма произведений соответствующих компонент векторов:

$$
\vec{a} \cdot \vec{b} = a_1 \cdot b_1 + a_2 \cdot b_2 + \dots + a_n \cdot b_n = \sum_{i=1}^{n} a_i \cdot b_i
$$

где:\
$\vec{a} = [a_1, a_2, \dots, a_n]$ — вектор в $N$-мерном пространстве,\
$\vec{b} = [b_1, b_2, \dots, b_n]$ — вектор в $N$-мерном пространстве. 

**Евклидова норма**:

Норма вектора, его длина, вычисляется по формуле евклидовой нормы, которая является обобщением теоремы Пифагора для многомерного пространства.

- В двумерном пространстве длина вектора $[x, y]$ вычисляется как $\sqrt{x^2 + y^2}$ (по теореме Пифагора).
- В трехмерном пространстве для вектора $[x, y, z]$ длина будет $\sqrt{x^2 + y^2 + z^2}$.
- Для вектора с $N$ измерениями:

$$
|\vec{a}| = \sqrt{a_1^2 + a_2^2 + \dots + a_n^2}
$$  

где:\
$\vec{a} = [a_1, a_2, \dots, a_n]$ — вектор в $N$-мерном пространстве,\
$|\vec{a}|$ — его длина (евклидова норма).

#### Как это работает:

1. Для каждого пользователя из базы данных вычисляется косинусное сходство с новым пользователем.  
2. На основе полученных значений определяется индекс пользователя с максимальным сходством.  
3. Возвращается результат — индекс самого похожего пользователя.  

---

### Примеры  

#### Случай 1: Векторы сонаправлены  
- Новый пользователь: $[0, 1, 2, 0, 0, 0]$  
- Пользователь из базы: $[0, 3, 6, 0, 0, 0]$ (в 3 раза активнее, но пропорции те же)  

##### Вычисления:

$$
\vec{a} \cdot \vec{b} = 0 \cdot 0 + 1 \cdot 3 + 2 \cdot 6 + 0 \cdot 0 + 0 \cdot 0 + 0 \cdot 0 = 15
$$

$$
|\vec{a}| = \sqrt{0^2 + 1^2 + 2^2 + 0^2 + 0^2 + 0^2} = \sqrt{5}
$$

$$
|\vec{b}| = \sqrt{0^2 + 3^2 + 6^2 + 0^2 + 0^2 + 0^2} = \sqrt{45}
$$

$$
cos(\theta) = \frac{15}{\sqrt{5} \times \sqrt{45}} = 1 \space (\text{идеальное сходство})
$$  

#### Случай 2: Векторы перпендикулярны  
- Новый пользователь: $[0, 1, 2, 0, 0, 0]$  
- Пользователь из базы: $[0, 0, 0, 5, 0, 0]$ (активен в другой категории)  

##### Вычисления:

$$
\vec{a} \cdot \vec{b} = 0 \cdot 0 + 1 \cdot 0 + 2 \cdot 0 + 0 \cdot 5 + 0 \cdot 0 + 0 \cdot 0 = 0
$$

$$
cos(\theta) = 0 \space (\text{нет связи})
$$

---

### Результаты  

Функция успешно находит наиболее похожего пользователя из базы данных. Например:  

```python
import numpy as np

users_stats = np.array(
    [
        [2, 1, 0, 0, 0, 0],
        [1, 1, 2, 1, 0, 0],
        [2, 0, 1, 0, 0, 0],
        [1, 1, 2, 1, 0, 1],
        [0, 0, 1, 2, 0, 0],
        [0, 0, 0, 0, 0, 5],
        [1, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 3],
        [1, 0, 0, 2, 1, 4]
    ]
)

new_user_stats = np.array([0, 1, 2, 0, 0, 0])

def similar_user(new_user_stats, users_stats):
    new_user_length = np.linalg.norm(new_user_stats)
    cosine_similarity = []

    for user in users_stats:
        old_user_length = np.linalg.norm(user)
        if old_user_length == 0 or new_user_length == 0:
            cosinus = 0
        else:
            cosinus = np.dot(new_user_stats, user) / (new_user_length * old_user_length)
        cosine_similarity.append(cosinus)
    
    most_similar_index = cosine_similarity.index(max(cosine_similarity))
    return f'Пользователь из базы с индексом: {most_similar_index} является наиболее похожим.'

result = similar_user(new_user_stats, users_stats)
print(result)
