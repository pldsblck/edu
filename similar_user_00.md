# Поиск близости через данные  

## Или как алгоритмы научились понимать человеческие предпочтения  

---

### Задача  

#### Основные функции:  
1. **Поиск похожих пользователей**: Найти существующего пользователя из базы данных, который максимально схож с новым пользователем по его поведению и предпочтениям.  
2. **Анализ поведенческих паттернов**: Определить категории активности, которые наиболее влияют на схожесть между пользователями.  

#### Почему этот проект особенный?  
- Он использует векторное представление пользователей для анализа многомерных данных.  
- Применяет косинусное сходство — метрику, которая эффективно работает в высокоразмерных пространствах.  
- Может быть адаптирован для различных задач, таких как рекомендательные системы, кластеризация или обнаружение аномалий.  

---

### Зачем это нужно?  

1. **Рекомендательные системы**: Если новый пользователь похож на пользователя X, ему можно предлагать тот же контент или товары.  
2. **Кластеризация данных**: Новый пользователь может быть автоматически отнесен к группе схожих пользователей, что помогает в сегментации аудитории.  
3. **Поиск аномалий**: Если сходство нового пользователя с существующими низкое, это может указывать на подозрительную активность или уникальные предпочтения.  

---

### Данные  

Данные о пользователях хранятся в виде матрицы, где каждая строка — это вектор, описывающий поведение конкретного человека. Матрица `users_stats` содержит данные о 10 пользователях, а новый пользователь представлен вектором `new_user_stats`.  

| User ID | Смартфон | Телевизор | Ноутбук | Шкаф | Холодильник | Посуда |  
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |  
| 1 | 2 | 1 | 0 | 0 | 0 | 0 |  
| 2 | 1 | 1 | 2 | 1 | 0 | 0 |  
| 3 | 2 | 0 | 1 | 0 | 0 | 0 |  
| 4 | 1 | 1 | 2 | 1 | 0 | 1 |  
| 5 | 0 | 0 | 1 | 2 | 0 | 0 |  
| 6 | 0 | 0 | 0 | 0 | 0 | 5 |  
| 7 | 1 | 0 | 0 | 0 | 0 | 0 |  
| 8 | 0 | 1 | 1 | 0 | 0 | 0 |  
| 9 | 0 | 0 | 0 | 1 | 1 | 3 |  
| 10 | 1 | 0 | 0 | 2 | 1 | 4 |  

или так:

$$
users \textunderscore stats_{m,n} =
\begin{bmatrix}
  \vec{a_1} \\
  \vec{a_2} \\
  \vdots  \\
  \vec{a_m}
\end{bmatrix} =
\begin{bmatrix}
  a_{1,1} & a_{1,2} & \cdots & a_{1,n} \\
  a_{2,1} & a_{2,2} & \cdots & a_{2,n} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  a_{m,1} & a_{m,2} & \cdots & a_{m,n}
\end{bmatrix}
$$

где:
- $m$ — количество пользователей в данных интернет-магазина,
- $n$ — количество столбцов по количеству категорий активности.

---

### Решение  

1. **Каждый человек — это вектор**:  
   - Каждый пользователь представляется в виде вектора в многомерном пространстве, где каждая ось соответствует определенной категории активности (например, частота покупок смартфонов, телевизоров и т.д.).  
   - Матрица `users_stats` — это набор векторов в 6-мерном пространстве.  

2. **Мера схожести**:  
   - Косинусное сходство $\cos(\theta)$ используется для сравнения направлений векторов.  
   - Формула косинусного сходства:

$$
cos(\theta) = \frac{\vec{a} \cdot \vec{b}}{|\vec{a}| \cdot |\vec{b}|}
$$

где:
$\vec{a}$ и $\vec{b}$ — векторы новых и существующих пользователей соответственно.
$|\vec{a}|$ и $|\vec{b}|$ — нормы (длины) векторов.  

3. **Скалярное произведение**:  
   - Вычисляется как сумма произведений соответствующих компонент векторов:

$$
\vec{a} \cdot \vec{b} = a_1 \cdot b_1 + a_2 \cdot b_2 + \dots + a_n \cdot b_n
$$  

4. **Евклидова норма**:  
   - Длина вектора вычисляется по формуле:

$$
|\vec{a}| = \sqrt{a_1^2 + a_2^2 + \dots + a_n^2}
$$  

#### Как это работает  

1. Для каждого пользователя из базы данных вычисляется косинусное сходство с новым пользователем.  
2. На основе полученных значений определяется индекс пользователя с максимальным сходством.  
3. Возвращается результат — индекс самого похожего пользователя.  

---

### Примеры  

#### Пример использования  

##### Случай 1: Векторы сонаправлены  
- Новый пользователь: $[0, 1, 2, 0, 0, 0]$  
- Пользователь из базы: $[0, 3, 6, 0, 0, 0]$ (в 3 раза активнее, но пропорции те же)  

Вычисления:

$$
\vec{a} \cdot \vec{b} = 0 \cdot 0 + 1 \cdot 3 + 2 \cdot 6 + 0 \cdot 0 + 0 \cdot 0 + 0 \cdot 0 = 15
$$

$$
|\vec{a}| = \sqrt{0^2 + 1^2 + 2^2 + 0^2 + 0^2 + 0^2} = \sqrt{5}
$$

$$
|\vec{b}| = \sqrt{0^2 + 3^2 + 6^2 + 0^2 + 0^2 + 0^2} = \sqrt{45}
$$

$$
cos(\theta) = \frac{15}{\sqrt{5} \times \sqrt{45}} = 1 \space (\text{идеальное сходство})
$$  

##### Случай 2: Векторы перпендикулярны  
- Новый пользователь: $[0, 1, 2, 0, 0, 0]$  
- Пользователь из базы: $[0, 0, 0, 5, 0, 0]$ (активен в другой категории)  

Вычисления:
$$
\vec{a} \cdot \vec{b} = 0 \cdot 0 + 1 \cdot 0 + 2 \cdot 0 + 0 \cdot 5 + 0 \cdot 0 + 0 \cdot 0 = 0
$$  
$$
cos(\theta) = 0 \space (\text{нет связи})
$$  

---

### Результаты  

Функция успешно находит наиболее похожего пользователя из базы данных. Например:  

```python
import numpy as np

users_stats = np.array(
    [
        [2, 1, 0, 0, 0, 0],
        [1, 1, 2, 1, 0, 0],
        [2, 0, 1, 0, 0, 0],
        [1, 1, 2, 1, 0, 1],
        [0, 0, 1, 2, 0, 0],
        [0, 0, 0, 0, 0, 5],
        [1, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 3],
        [1, 0, 0, 2, 1, 4]
    ]
)

new_user_stats = np.array([0, 1, 2, 0, 0, 0])

def similar_user(new_user_stats, users_stats):
    new_user_length = np.linalg.norm(new_user_stats)
    cosine_similarity = []

    for user in users_stats:
        old_user_length = np.linalg.norm(user)
        if old_user_length == 0 or new_user_length == 0:
            cosinus = 0
        else:
            cosinus = np.dot(new_user_stats, user) / (new_user_length * old_user_length)
        cosine_similarity.append(cosinus)
    
    most_similar_index = cosine_similarity.index(max(cosine_similarity))
    return f'Пользователь из базы с индексом: {most_similar_index} является наиболее похожим.'

result = similar_user(new_user_stats, users_stats)
print(result)
