# Проект: Поиск похожих пользователей через векторное представление

## Или все ли мы такие разные?

### Задача

Написать функцию, которая решает задачу поиска пользователя, наиболее похожего на нового пользователя по их характеристикам. Смысловая задача — определить, какой из существующих пользователей `users_stats` имеет наиболее схожее поведение/предпочтения с новым пользователем `new_user_stats`.

### Зачем это нужно?
- **Рекомендательные системы**: Если новый пользователь похож на пользователя X, ему можно предлагать тот же контент.
- **Кластеризация данных**: Новый пользователь может быть автоматически отнесен к группе схожих пользователей.
- **Поиск аномалий**: Если сходство с всеми пользователями низкое, это может быть подозрительный аккаунт.

---

### Данные

Данные о пользователях хранятся в виде матрицы, где каждая строка — это вектор, описывающий поведение конкретного человека. Матрица `users_stats` содержит данные о 10 пользователях, а новый пользователь представлен вектором `new_user_stats`. Например:

| User ID | Смартфон | Телевизор | Ноутбук | Шкаф | Холодильник | Посуда |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 1 | 2 | 1 | 0 | 0 | 0 | 0 |
| 2 | 1 | 1 | 2 | 1 | 0 | 0 |
| 3 | 2 | 0 | 1 | 0 | 0 | 0 |
| 4 | 1 | 1 | 2 | 1 | 0 | 1 |
| 5 | 0 | 0 | 1 | 2 | 0 | 0 |
| 6 | 0 | 0 | 0 | 0 | 0 | 5 |
| 7 | 1 | 0 | 0 | 0 | 0 | 0 |
| 8 | 0 | 1 | 1 | 0 | 0 | 0 |
| 9 | 0 | 0 | 0 | 1 | 1 | 3 |
| 10 | 1 | 0 | 0 | 2 | 1 | 4 |

---

## Обоснование

### Каждый человек — это вектор

Представим, что мы пытаемся понять, насколько два человека похожи друг на друга, основываясь на их вкусах. Чтобы реализовать алгоритм сравнения пользователей, нам понадобится линейная алгебра (скалярное произведение, нормы) и векторное представление наших данных о пользователях.

$$
\vec{a} = [a_1, a_2, \dots, a_n]
$$

или

$$
\vec{\text{new}\textunderscore\text{user}\textunderscore\text{stats}} = [0, 1, 2, 0, 0, 0]
$$

Каждый человек — это стрелка, он же вектор, в многомерном пространстве, где каждая ось — категория активности (смартфон, телевизор, ноутбук и т.д.). По сути матрица `users_stats` — это 10 векторов в 6-мерном пространстве, а `new_user_stats` — это всего лишь один вектор в таком же 6-мерном пространстве.


$$
users \textunderscore stats_{m,n} =
\begin{bmatrix}
  \vec{a_1} \\
  \vec{a_2} \\
  \vdots  \\
  \vec{a_m}
\end{bmatrix} =
\begin{bmatrix}
  a_{1,1} & a_{1,2} & \cdots & a_{1,n} \\
  a_{2,1} & a_{2,2} & \cdots & a_{2,n} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  a_{m,1} & a_{m,2} & \cdots & a_{m,n}
\end{bmatrix}
$$

где:
- $m$ — количество пользователей в данных интернет-магазина,
- $n$ — количество столбцов по количеству категорий активности.

---

### Мера схожести

#### 1. Как же измерить схожесть направления стрелок?
- Если стрелки указывают в одном направлении — вкусы пропорционально одинаковы.
- Если стрелки перпендикулярны — вкусы не связаны.
- Если стрелки направлены противоположно — вкусы противоположны.

#### 2. Угол между стрелками
- Угол между двумя стрелками — это мера их схожести.
- Чем меньше угол, тем ближе стрелки направлены — тем более похожи вкусы.

#### 3. Как вычислить угол?
Из школьного курса геометрии мы знаем, что косинус угла между двумя векторами можно найти через их скалярное произведение и длины по формуле косинусного сходства:

$$
cos(\theta) = \frac{\vec{a} \cdot \vec{b}}{|\vec{a}| \cdot |\vec{b}|}
$$

где:
- $\vec{a}$ и $\vec{b}$ — векторы нового пользователя `new_user_stats` и существующего пользователя из базы данных.

Для наглядности дальнейших вычислений нашу формулу косинусного сходства можно выразить еще вот так:

$$
cos(\theta) = \frac{\text{скалярное произведение}}{|\text{норма нового пользователя}| \times |\text{норма текущего пользователя}|}
$$

---

### Скалярное произведение

Скалярное произведение для двух векторов в $N$-мерном пространстве выглядит так:

$$
\vec{a} \cdot \vec{b} = a_1 \cdot b_1 + a_2 \cdot b_2 + \dots + a_n \cdot b_n = \sum_{i=1}^{n} a_i \cdot b_i
$$

где:
- $\vec{a} = [a_1, a_2, \dots, a_n]$ — вектор в $N$-мерном пространстве,
- $\vec{b} = [b_1, b_2, \dots, b_n]$ — вектор в $N$-мерном пространстве.

---

### Евклидова норма

Норма вектора, его длина, вычисляется по формуле евклидовой нормы, которая является обобщением теоремы Пифагора для многомерного пространства.

- В двумерном пространстве длина вектора $[x, y]$ вычисляется как $\sqrt{x^2 + y^2}$ (по теореме Пифагора).
- В трехмерном пространстве для вектора $[x, y, z]$ длина будет $\sqrt{x^2 + y^2 + z^2}$.
- Для вектора с $N$ измерениями:

$$
|\vec{a}| = \sqrt{a_1^2 + a_2^2 + \dots + a_n^2}
$$

где:
- $\vec{a} = [a_1, a_2, \dots, a_n]$ — вектор в $N$-мерном пространстве,
- $|\vec{a}|$ — его длина (евклидова норма).

---

## Примеры расчетов

### Случай 1: Векторы сонаправлены

- Новый пользователь `new_user_stats` = [0, 1, 2, 0, 0, 0].
- Пользователь из базы = [0, 3, 6, 0, 0, 0] (в 3 раза активнее, но пропорции те же).

Вычисляем их скалярное произведение:

$$
0 \cdot 0 + 1 \cdot 3 + 2 \cdot 6 + 0 \cdot 0 + 0 \cdot 0 + 0 \cdot 0 = 3 + 12 = 15
$$

Косинусное сходство:

$$
cos(\theta) = \frac{15}{\sqrt{5} \times \sqrt{45}} = \frac{15}{15} = 1 \space (\text{идеальное сходство})
$$

---

### Случай 2: Векторы перпендикулярны

- Новый пользователь `new_user_stats` = [0, 1, 2, 0, 0, 0].
- Пользователь из базы = [0, 0, 0, 5, 0, 0] (активен в другой категории).

Вычисляем их скалярное произведение:

$$
0 \cdot 0 + 1 \cdot 0 + 2 \cdot 0 + 0 \cdot 5 + 0 \cdot 0 + 0 \cdot 0 = 0
$$

Косинусное сходство:

$$
cos(\theta) = 0 \space (\text{нет связи})
$$

---

## Код на языке Python

```python
import numpy as np

users_stats = np.array(
    [
        [2, 1, 0, 0, 0, 0],
        [1, 1, 2, 1, 0, 0],
        [2, 0, 1, 0, 0, 0],
        [1, 1, 2, 1, 0, 1],
        [0, 0, 1, 2, 0, 0],
        [0, 0, 0, 0, 0, 5],
        [1, 0, 0, 0, 0, 0],
        [0, 1, 1, 0, 0, 0],
        [0, 0, 0, 1, 1, 3],
        [1, 0, 0, 2, 1, 4]
    ]
)

# Данные о новом пользователе
new_user_stats = np.array([0, 1, 2, 0, 0, 0])

def similar_user(new_user_stats, users_stats):
    # Вычисляем евклидову норму нового пользователя
    new_user_length = np.linalg.norm(new_user_stats)
    cosine_similarity = []

    for user in users_stats:
        # Вычисляем евклидову норму текущего пользователя
        old_user_length = np.linalg.norm(user)
        
        # Вычисляем косинусное сходство
        cosinus = np.dot(new_user_stats, user) / (new_user_length * old_user_length)
        cosine_similarity.append(cosinus)
    
    # Находим индекс максимального косинуса
    most_similar_index = cosine_similarity.index(max(cosine_similarity))
    return f'Пользователь из базы с индексом: {most_similar_index} является наиболее похожим.'

# Вызов функции
result = similar_user(new_user_stats, users_stats)
print(result)
```
